{"cells":[{"source":"<center><img src=\"car.jpg\" width=500></center>\n\n\nInsurance companies invest a lot of time and money into optimizing their pricing and accurately estimating the likelihood that customers will make a claim. In many countries insurance it is a legal requirement to have car insurance in order to drive a vehicle on public roads, so the market is very large!\n\n(`Source: https://www.accenture.com/_acnmedia/pdf-84/accenture-machine-leaning-insurance.pdf`) \n\nKnowing all of this, On the Road car insurance have requested your services in building a model to predict whether a customer will make a claim on their insurance during the policy period. As they have very little expertise and infrastructure for deploying and monitoring machine learning models, they've asked you to identify the single feature that results in the best performing model, as measured by accuracy, so they can start with a simple model in production.\n\nThey have supplied you with their customer data as a csv file called `car_insurance.csv`, along with a table detailing the column names and descriptions below.","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"id":"c3f0e974-faf8-458f-bf2a-06a469d0ea5e","cell_type":"markdown","attachments":{}},{"source":"\n\n## The dataset\n\n| Column | Description |\n|--------|-------------|\n| `id` | Unique client identifier |\n| `age` | Client's age: <br> <ul><li>`0`: 16-25</li><li>`1`: 26-39</li><li>`2`: 40-64</li><li>`3`: 65+</li></ul> |\n| `gender` | Client's gender: <br> <ul><li>`0`: Female</li><li>`1`: Male</li></ul> |\n| `driving_experience` | Years the client has been driving: <br> <ul><li>`0`: 0-9</li><li>`1`: 10-19</li><li>`2`: 20-29</li><li>`3`: 30+</li></ul> |\n| `education` | Client's level of education: <br> <ul><li>`0`: No education</li><li>`1`: High school</li><li>`2`: University</li></ul> |\n| `income` | Client's income level: <br> <ul><li>`0`: Poverty</li><li>`1`: Working class</li><li>`2`: Middle class</li><li>`3`: Upper class</li></ul> |\n| `credit_score` | Client's credit score (between zero and one) |\n| `vehicle_ownership` | Client's vehicle ownership status: <br><ul><li>`0`: Does not own their vehilce (paying off finance)</li><li>`1`: Owns their vehicle</li></ul> |\n| `vehcile_year` | Year of vehicle registration: <br><ul><li>`0`: Before 2015</li><li>`1`: 2015 or later</li></ul> |\n| `married` | Client's marital status: <br><ul><li>`0`: Not married</li><li>`1`: Married</li></ul> |\n| `children` | Client's number of children |\n| `postal_code` | Client's postal code | \n| `annual_mileage` | Number of miles driven by the client each year |\n| `vehicle_type` | Type of car: <br> <ul><li>`0`: Sedan</li><li>`1`: Sports car</li></ul> |\n| `speeding_violations` | Total number of speeding violations received by the client | \n| `duis` | Number of times the client has been caught driving under the influence of alcohol |\n| `past_accidents` | Total number of previous accidents the client has been involved in |\n| `outcome` | Whether the client made a claim on their car insurance (response variable): <br><ul><li>`0`: No claim</li><li>`1`: Made a claim</li></ul> |","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"id":"8928ffdf-25d6-4ad9-909f-0dd8d10b9a42","cell_type":"markdown"},{"source":"# Import required modules\nimport pandas as pd\nimport numpy as np\nfrom statsmodels.formula.api import logit\n\n#Final goal: Identify the single feature that produces the best accuracy in predicting whether a customer makes a claim.\n\n#1. Reading in and exploring the dataset\n\ndf = pd.read_csv(\"car_insurance.csv\")\n# Checking the actual data:\n#df.head(50)\nprint(df.columns)\n\n# Checking Dtypes-Non missing values-etc\n#df.info()\n\n# Too lazy to fix D-types\n\n# Checking Missing values\n#df.isna().sum() / len(df) * 100\n\n\n# Checking distributions:\n#df[\"age\"].value_counts()\n#df[\"gender\"].value_counts()\n#df[\"driving_experience\"].value_counts()\n#df[\"education\"].value_counts()\n#df[\"income\"].value_counts()\n#print(df[ ((df[\"credit_score\"]<0) | (df[\"credit_score\"]>1)) ][\"credit_score\"])\n#df[\"vehicle_ownership\"].value_counts()\n#df[\"vehicle_year\"].value_counts()\n#df[\"married\"].value_counts()\n#df[\"children\"].value_counts()\n#df[\"postal_code\"].value_counts()\n#df[\"annual_mileage\"].value_counts()\n#df[\"vehicle_type\"].value_counts()\n#df[\"speeding_violations\"].value_counts()\n#df[\"duis\"].value_counts()\n#df[\"past_accidents\"].value_counts()\n#df[\"outcome\"].value_counts()\n","metadata":{"executionTime":34,"id":"bA5ajAmk7XH6","lastSuccessfullyExecutedCode":"# Import required modules\nimport pandas as pd\nimport numpy as np\nfrom statsmodels.formula.api import logit\n\n#Final goal: Identify the single feature that produces the best accuracy in predicting whether a customer makes a claim.\n\n#1. Reading in and exploring the dataset\n\ndf = pd.read_csv(\"car_insurance.csv\")\n# Checking the actual data:\n#df.head(50)\nprint(df.columns)\n\n# Checking Dtypes-Non missing values-etc\n#df.info()\n\n# Too lazy to fix D-types\n\n# Checking Missing values\n#df.isna().sum() / len(df) * 100\n\n\n# Checking distributions:\n#df[\"age\"].value_counts()\n#df[\"gender\"].value_counts()\n#df[\"driving_experience\"].value_counts()\n#df[\"education\"].value_counts()\n#df[\"income\"].value_counts()\n#print(df[ ((df[\"credit_score\"]<0) | (df[\"credit_score\"]>1)) ][\"credit_score\"])\n#df[\"vehicle_ownership\"].value_counts()\n#df[\"vehicle_year\"].value_counts()\n#df[\"married\"].value_counts()\n#df[\"children\"].value_counts()\n#df[\"postal_code\"].value_counts()\n#df[\"annual_mileage\"].value_counts()\n#df[\"vehicle_type\"].value_counts()\n#df[\"speeding_violations\"].value_counts()\n#df[\"duis\"].value_counts()\n#df[\"past_accidents\"].value_counts()\n#df[\"outcome\"].value_counts()\n","executionCancelledAt":null,"lastExecutedAt":1756471855643,"lastExecutedByKernel":"a4992b46-7636-4a5d-ad44-c64b1bdc25fa","lastScheduledRunId":null,"outputsMetadata":{"0":{"height":122,"type":"stream"},"1":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"1dff816a-e9b5-4a95-9a00-200b24aaf3a9","nodeType":"const"}}}}},"id":"d0eb4f16-5a99-460d-a5ba-706b7ef0bbe7","cell_type":"code","execution_count":224,"outputs":[{"output_type":"stream","name":"stdout","text":"Index(['id', 'age', 'gender', 'driving_experience', 'education', 'income',\n       'credit_score', 'vehicle_ownership', 'vehicle_year', 'married',\n       'children', 'postal_code', 'annual_mileage', 'vehicle_type',\n       'speeding_violations', 'duis', 'past_accidents', 'outcome'],\n      dtype='object')\n"}]},{"source":"#2. Filling missing values\n\n# missing values in credit_score and annual_mileage >5% so the best solution is to impute\n# and not droping the values\n\n# credit_score with 9.82% missing values and annual_mileage with 9.57%\ndf[\"credit_score\"].fillna(df[\"credit_score\"].median(), inplace = True)\n#df[\"credit_score\"].isna().sum()\n\ndf[\"annual_mileage\"].fillna(df[\"annual_mileage\"].median(), inplace = True)\n#df[\"annual_mileage\"].isna().sum()","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1756471855691,"lastExecutedByKernel":"a4992b46-7636-4a5d-ad44-c64b1bdc25fa","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#2. Filling missing values\n\n# missing values in credit_score and annual_mileage >5% so the best solution is to impute\n# and not droping the values\n\n# credit_score with 9.82% missing values and annual_mileage with 9.57%\ndf[\"credit_score\"].fillna(df[\"credit_score\"].median(), inplace = True)\n#df[\"credit_score\"].isna().sum()\n\ndf[\"annual_mileage\"].fillna(df[\"annual_mileage\"].median(), inplace = True)\n#df[\"annual_mileage\"].isna().sum()","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"1dff816a-e9b5-4a95-9a00-200b24aaf3a9","nodeType":"const"}}}}},"cell_type":"code","id":"f73c6f2b-bd7f-40a6-9197-92ea9069e1f1","outputs":[],"execution_count":225},{"source":"#3. Preparing for modeling\n\n# Creating a list to store the models\nmodels = []\n\n# Storing the features as a variable\nfeatures = list(df.columns[1:-1])\n#print(features)\n","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1756471855747,"lastExecutedByKernel":"a4992b46-7636-4a5d-ad44-c64b1bdc25fa","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#3. Preparing for modeling\n\n# Creating a list to store the models\nmodels = []\n\n# Storing the features as a variable\nfeatures = list(df.columns[1:-1])\n#print(features)\n","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"82d3786f-6bc1-457e-859d-6057894168be","outputs":[],"execution_count":226},{"source":"#4. Building and storing the models\n\n#Modeling with a for loop\nfor f in features:\n    model = logit(f\"outcome ~ {f}\",data = df).fit()\n    models.append(model)\n\n#for m in models:\n    #print(m.params)\n","metadata":{"executionCancelledAt":null,"executionTime":2554,"lastExecutedAt":1756471858302,"lastExecutedByKernel":"a4992b46-7636-4a5d-ad44-c64b1bdc25fa","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#4. Building and storing the models\n\n#Modeling with a for loop\nfor f in features:\n    model = logit(f\"outcome ~ {f}\",data = df).fit()\n    models.append(model)\n\n#for m in models:\n    #print(m.params)\n","outputsMetadata":{"0":{"height":502,"type":"stream"}}},"cell_type":"code","id":"d9f2ab33-7d30-43af-9509-cb56c5c6a41c","outputs":[{"output_type":"stream","name":"stdout","text":"Optimization terminated successfully.\n         Current function value: 0.511794\n         Iterations 6\nOptimization terminated successfully.\n         Current function value: 0.615951\n         Iterations 5\nOptimization terminated successfully.\n         Current function value: 0.467092\n         Iterations 8\nOptimization terminated successfully.\n         Current function value: 0.603742\n         Iterations 5\nOptimization terminated successfully.\n         Current function value: 0.531499\n         Iterations 6\nOptimization terminated successfully.\n         Current function value: 0.572649\n         Iterations 5\nOptimization terminated successfully.\n         Current function value: 0.552412\n         Iterations 5\nOptimization terminated successfully.\n         Current function value: 0.572668\n         Iterations 6\nOptimization terminated successfully.\n         Current function value: 0.586659\n         Iterations 5\nOptimization terminated successfully.\n         Current function value: 0.595431\n         Iterations 5\nOptimization terminated successfully.\n         Current function value: 0.617345\n         Iterations 5\nOptimization terminated successfully.\n         Current function value: 0.605605\n         Iterations 5\nOptimization terminated successfully.\n         Current function value: 0.621700\n         Iterations 5\nOptimization terminated successfully.\n         Current function value: 0.558922\n         Iterations 7\nOptimization terminated successfully.\n         Current function value: 0.598699\n         Iterations 6\nOptimization terminated successfully.\n         Current function value: 0.549220\n         Iterations 7\n"}],"execution_count":227},{"source":"#5. Measuring performance\n\nactual_outcomes = df[\"outcome\"]\n\nmodel_accuracies = []\nfor model in models:\n    #predict\n    predicted_outcomes = np.round(model.predict())\n\n    #compare results:\n    resu = pd.DataFrame({\n        \"actual_outcome\":actual_outcomes,\n        \"predicted_outcome\":predicted_outcomes\n    })\n    resu = resu.value_counts(sort=False)\n    #print(resu)\n\n    #confusion matrix:\n    conf_matrix = model.pred_table()\n    #print(conf_matrix)\n\n    #extract values from conf matrix:\n    TN = conf_matrix[0,0] \n    TP = conf_matrix[1,1]\n    FN = conf_matrix[1,0]\n    FP = conf_matrix[0,1]\n\n    #calculate and append accuracy:\n    accuracy = (TN + TP) / (TN + FN + FP + TP)\n    model_accuracies.append(accuracy)\n    \n","metadata":{"executionCancelledAt":null,"executionTime":504,"lastExecutedAt":1756471858806,"lastExecutedByKernel":"a4992b46-7636-4a5d-ad44-c64b1bdc25fa","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#5. Measuring performance\n\nactual_outcomes = df[\"outcome\"]\n\nmodel_accuracies = []\nfor model in models:\n    #predict\n    predicted_outcomes = np.round(model.predict())\n\n    #compare results:\n    resu = pd.DataFrame({\n        \"actual_outcome\":actual_outcomes,\n        \"predicted_outcome\":predicted_outcomes\n    })\n    resu = resu.value_counts(sort=False)\n    #print(resu)\n\n    #confusion matrix:\n    conf_matrix = model.pred_table()\n    #print(conf_matrix)\n\n    #extract values from conf matrix:\n    TN = conf_matrix[0,0] \n    TP = conf_matrix[1,1]\n    FN = conf_matrix[1,0]\n    FP = conf_matrix[0,1]\n\n    #calculate and append accuracy:\n    accuracy = (TN + TP) / (TN + FN + FP + TP)\n    model_accuracies.append(accuracy)\n    \n","outputsMetadata":{"0":{"height":502,"type":"stream"}}},"cell_type":"code","id":"cb9e994c-b7bf-4a15-8394-45a19275fdd0","outputs":[],"execution_count":228},{"source":"#6. Finding the best performing model\n\n#Identifying the index of accuracies with the largest score\nbest_accuracy = max(model_accuracies)\nbest_model_index = model_accuracies.index(best_accuracy)\n\n#Mapping the highest accuracy to the feature\nbest_model = models[best_model_index]\nbest_feature = best_model.params.index[1].split('[')[0]\n#print(best_feature)\n\n#final results:\nbest_feature_df = pd.DataFrame({\n    \"best_feature\":[best_feature],\n    \"best_accuracy\":[best_accuracy]\n})\n\nprint(best_feature_df)","metadata":{"executionCancelledAt":null,"executionTime":96,"lastExecutedAt":1756471858904,"lastExecutedByKernel":"a4992b46-7636-4a5d-ad44-c64b1bdc25fa","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#6. Finding the best performing model\n\n#Identifying the index of accuracies with the largest score\nbest_accuracy = max(model_accuracies)\nbest_model_index = model_accuracies.index(best_accuracy)\n\n#Mapping the highest accuracy to the feature\nbest_model = models[best_model_index]\nbest_feature = best_model.params.index[1].split('[')[0]\n#print(best_feature)\n\n#final results:\nbest_feature_df = pd.DataFrame({\n    \"best_feature\":[best_feature],\n    \"best_accuracy\":[best_accuracy]\n})\n\nprint(best_feature_df)","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"5beb4994-252b-4dd3-9950-830159dea3c5","outputs":[{"output_type":"stream","name":"stdout","text":"         best_feature  best_accuracy\n0  driving_experience         0.7771\n"}],"execution_count":229}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}
